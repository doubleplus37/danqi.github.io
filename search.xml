<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>My first blog</title>
    <url>/posts/11206.html</url>
    <content><![CDATA[<p>为了组队记录自己的学习过程注册的Blog,希望今后能够坚持下来！</p>
<p>网站是根据这一篇博客建立的：<a href="https://echoshanyushi.github.io/2020/02/07/34289/">here</a></p>
]]></content>
      <tags>
        <tag>单琦</tag>
      </tags>
  </entry>
  <entry>
    <title>datawhale机器学习第一课(logit回归)</title>
    <url>/posts/cf91a0de.html</url>
    <content><![CDATA[<h2 id="1-摘要"><a href="#1-摘要" class="headerlink" title="1.摘要"></a>1.摘要</h2><p>logit回归是一种二元或多元回归，属于广义线性回归。其与一般的线性回归的区别在于：logit回归值为离散，而线性回归值为连续。其通常用于分类问题，从机器学习的角度来说，其属于监督学习，即在训练时同时给出预测结果，这是其与聚类分析的差别。logit回归使用的是非线性模型，因为其引入了<code>sigmod函数</code>:$y=\frac{1}{1+e^{-z}}$，其中$z = \theta^T·x$，$\theta$为要训练的参数。</p>
<a id="more"></a>
<h2 id="2-内容"><a href="#2-内容" class="headerlink" title="2.内容"></a>2.内容</h2><blockquote>
<p> <strong>思考以及学习的内容围绕助教的5个问题</strong></p>
</blockquote>
<ol>
<li>什么是逻辑回归，逻辑回归的推导，损失函数的推导 </li>
<li>逻辑回归与SVM的异同 </li>
<li>逻辑回归与线性回归的不同 </li>
<li>为什么LR需要归一化或者取对数，为什么LR把特征离散化后效果更好 </li>
<li>LR为什么用Sigmoid函数，这个函数有什么优缺点，为什么不用其他函数</li>
</ol>
<h3 id="2-1-什么是逻辑回归？"><a href="#2-1-什么是逻辑回归？" class="headerlink" title="2.1 什么是逻辑回归？"></a>2.1 什么是逻辑回归？</h3><p><strong>1.概念</strong></p>
<p>所谓逻辑回归，本质上是一个分类问题，其预测值为一组离散值，在模型中一般不直接预测结果的值，<strong>而是预测每个离散结果出现的概率</strong>，并且选取出现概率最大的值作为预测值。在二元逻辑回归就常表现为选取概率大于0.5的一方，即将$z=0$作为决策边界。</p>
<p><strong>2.逻辑回归推导</strong></p>
<p>…不明觉厉</p>
<p><strong>3.损失函数的推导</strong></p>
<p>所谓损失函数，就是衡量模式对于训练数据的预测值与真实值之间的差异程度，是训练模型的重要一环，一般来说，模型的训练都会朝着损失函数减小的方向进行。</p>
<blockquote>
<p>这里借鉴一下其他大佬的总结：</p>
<ul>
<li><p>选择代价函数时，最好挑选对参数$\theta$可微的函数（全微分存在，偏导数一定存在）</p>
</li>
<li><p>对于每种算法来说，代价函数不是唯一的；</p>
</li>
<li><p>代价函数是参数 $\theta$的函数；</p>
</li>
<li><p>总的代价函数 $J(\theta)$ 可以用来评价模型的好坏，代价函数越小说明模型和参数越符合训练样本 $(x,y)$ ；</p>
</li>
<li><p>$J(\theta)$ 是一个标量；</p>
<p>链接:<a href="https://zhuanlan.zhihu.com/p/28408516">https://zhuanlan.zhihu.com/p/28408516</a></p>
</li>
</ul>
</blockquote>
<p><strong>对于二元逻辑回归的损失函数具体推导如下</strong></p>
<p>假设y只能取0或1</p>
<script type="math/tex; mode=display">
P(y=0\mid x;\theta)=h_\theta(x)\\
P(y=1\mid x;\theta)=1-h_\theta(x)</script><p>将这两个公式统一起来</p>
<script type="math/tex; mode=display">
P(y\mid x;\theta) = h_\theta(x)^{1-y}+(1-h_\theta(x))^y</script><p>上面这个公式是针对某一个y值建立的，即针对一个样本；但是模型的建立是通过训练一组样本，即总体最优化。</p>
<p><strong>建立似然函数</strong></p>
<script type="math/tex; mode=display">
P(y\mid x;\theta) = \prod h_\theta(x_i)^{1-y_i}+(1-h_\theta(x_i))^y_i</script><p>这里采用似然函数建立模型，表示以样本x为预测因子，并且以计算出来的$\theta$作为分布的参数，发生样本y(y为一组)发生的概率最大，其与损失函数结果类似，但思想略有不同。当然还有通过信息熵方面的理论含义来直接建立损失函数。</p>
<p><strong>对数似然</strong></p>
<script type="math/tex; mode=display">
lnP(y\mid x;\theta) = \sum (1-y_i)h_\theta(x_i)+y_i(1-h_\theta(x_i))</script><p>用样本训练$\theta$使得$lnP$最大，如果令$C=-\frac{1}{M}lnP$，则C的含义类似于损失函数，要训练使得C最小。</p>
<h3 id="2-2-SVM与逻辑回归的不同"><a href="#2-2-SVM与逻辑回归的不同" class="headerlink" title="2.2 SVM与逻辑回归的不同"></a>2.2 SVM与逻辑回归的不同</h3><p>还没有看SVM的部分，先占坑，过几天补。。。</p>
<h3 id="2-3-逻辑回归与线性回归的差别"><a href="#2-3-逻辑回归与线性回归的差别" class="headerlink" title="2.3 逻辑回归与线性回归的差别"></a>2.3 逻辑回归与线性回归的差别</h3><p>逻辑回归与线性回归同属广义线性回归模型，但主要的差别如下：</p>
<ol>
<li>逻辑回归本质是一个分类问题，而线性回归则是回归问题。这一点也体现在预测量上，逻辑回归中预测量为离散值，而线性回归则为连续值。</li>
<li>逻辑回归表面上<strong>因变量</strong>是离散值，但其实际模型的预测量是概率，是一个连续值，只不过通过概率的大小来给出离散值的结果，因此离散和连续的特点并不直接表现在模型的关键部分。</li>
<li>线性回归假设因变量为高斯分布，而2分类问题假设因变量为伯努利分布(概率论知识，网上看的，不明觉厉)</li>
<li>采用的损失函数不同，线性回归的损失函数是以最小二乘法为基础，即选用平方损失函数。</li>
</ol>
<h3 id="2-4-为什么LR需要归一化或者取对数，为什么LR把特征离散化后效果更好-？"><a href="#2-4-为什么LR需要归一化或者取对数，为什么LR把特征离散化后效果更好-？" class="headerlink" title="2.4 为什么LR需要归一化或者取对数，为什么LR把特征离散化后效果更好 ？"></a>2.4 为什么LR需要归一化或者取对数，为什么LR把特征离散化后效果更好 ？</h3><blockquote>
<p> 为什么LR需要归一化或者对数？</p>
</blockquote>
<p>不同特征的量级不同，而量级差异会使得采用迭代方法计算参数$\theta$收敛的很慢或者不能收敛。</p>
<p><img src="../images/datawhale%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%AC%E4%B8%80%E8%AF%BE(logit%E5%9B%9E%E5%BD%92" alt="img">/20160517192219846)</p>
<p>如上图，会使得用于梯度下降的等高线变得更“圆”，而不是椭圆。</p>
<p>图片链接：<a href="https://blog.csdn.net/weixin_38111819/article/details/79729444">https://blog.csdn.net/weixin_38111819/article/details/79729444</a></p>
<blockquote>
<p>为什么LR把特征离散化后效果会更好？</p>
</blockquote>
<p>这个问题好复杂…从来没有想过这个问题，看了一下网上的答案，主要的原因包括：可以使得运算速度变快(从迭代变快以及稀疏向量内积的方向考虑)；增加鲁棒性；增加模型的非线性属性(可以将单变量离散为N个，每个变量就有了单独的权重)；降低了过拟合风险。</p>
<p>很多不太能理解，先占坑<a href="https://www.zhihu.com/question/31989952">https://www.zhihu.com/question/31989952</a></p>
<h3 id="2-5-LR为什么选用sigmod函数"><a href="#2-5-LR为什么选用sigmod函数" class="headerlink" title="2.5 LR为什么选用sigmod函数"></a>2.5 LR为什么选用sigmod函数</h3><p>其实二分类问题最简单的判断函数为：</p>
<script type="math/tex; mode=display">
f(x)=\left\{
\begin{aligned}
1(x>0) \\
0.5(x=0) \\
0(x<0)
\end{aligned}
\right.</script><p>但是跃迁函数在$x=0$不可微会带来很多问题，而<code>sigmod</code>函数则不存在这个问题，其在<code>x=0</code>即$f(x)=\frac12$处是敏感的，即具有跃迁函数的性质，在$z=\frac12$处x微小的差异就可以使得z有较大的差异，从而利于分类。</p>
<p>而对于缺点：主要是这个函数的输出不是均值为0的，因此假设输入均为正数（或负数），那么对w的导数总是正数（或负数），使得收敛缓慢。此外,<code>sigmod</code>函数作为指数函数计算较慢。</p>
<p>参考链接：<a href="https://zhuanlan.zhihu.com/p/71882757">https://zhuanlan.zhihu.com/p/71882757</a></p>
<p><a href="https://blog.csdn.net/NOT_GUY/article/details/78749509">https://blog.csdn.net/NOT_GUY/article/details/78749509</a></p>
<blockquote>
<p>关于为什么选用sigmod函数，网络上的解释太概率论，等看懂了再回来。</p>
</blockquote>
]]></content>
      <categories>
        <category>datawhale机器学习入门</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>datawhale</tag>
        <tag>机器学习入门</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习初学课程</title>
    <url>/posts/4661ff3d.html</url>
    <content><![CDATA[<h2 id="1-导论"><a href="#1-导论" class="headerlink" title="1.导论"></a>1.导论</h2><ul>
<li>ML用于数据挖掘、推荐系统、以及学习人类大脑如何运作。</li>
</ul>
<blockquote>
<p>什么是机器学习？</p>
</blockquote>
<p>Arthur Samuel(1959)：gives computers the ability to learn without being explicitly programmed.</p>
<p>Tom Mitchell(1998): 对于任务T，通过完成T的经验E，来提高对于任务T的完成率。</p>
<a id="more"></a>
<h2 id="2-监督以及无监督学习"><a href="#2-监督以及无监督学习" class="headerlink" title="2.监督以及无监督学习"></a>2.监督以及无监督学习</h2><ul>
<li>监督学习：给出一系列<strong>真实的</strong>输入，并告诉了其对应的输出，从而对其建模，比如回归问题、分类问题</li>
<li>无监督学习：没有给出正确的答案，只是给出一组数据，让机器自己找出结构。比如分类算法</li>
</ul>
<p>无监督学习就像给你39年的降水数据，自动帮你识别出特征(类似于EOF)，比如南方多雨、北方少雨；而对于监督学习就是你除了给机器39年降水数据外，你还要告诉它这一年究竟是属于哪一种，比如三类雨型的某种，从而建立模型，之后就利用模型预测。</p>
<h2 id="3-模型描述"><a href="#3-模型描述" class="headerlink" title="3.模型描述"></a>3.模型描述</h2><p><strong>h -&gt; hypothesis</strong></p>
<p><img src="/images/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%E5%90%B4%E6%81%A9%E8%BE%BE1/image-20200817181232325.png" alt="image-20200817181232325"></p>
<p><img src="/images/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%E5%90%B4%E6%81%A9%E8%BE%BE1/image-20200817185203513.png" alt="image-20200817185203513"></p>
<h3 id="3-1-代价函数-cost-function"><a href="#3-1-代价函数-cost-function" class="headerlink" title="3.1 代价函数(cost function)"></a>3.1 代价函数(cost function)</h3><p>目的是为了得到最优的参数，比如线性回归就是最小二乘函数<strong>最小</strong></p>
<p><img src="/images/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%E5%90%B4%E6%81%A9%E8%BE%BE1/image-20200817185241613.png" alt="image-20200817185241613"></p>
<p>代价函数的参数为(θ0，θ1)，老师没有直接用导数的方法来求得最优化值，而是画出了代价函数 <strong>J</strong> 随θ的变化图像，二维参数使用等高线。</p>
<h3 id="3-2-梯度下降"><a href="#3-2-梯度下降" class="headerlink" title="3.2 梯度下降"></a>3.2 梯度下降</h3><p>最优化任意函数 <strong>J(θ,…)</strong></p>
<blockquote>
<p>步骤</p>
</blockquote>
<ul>
<li>给定参数初值</li>
<li>从初值开始，找到一个下降最快的方向，前进一小步</li>
<li>不断前进</li>
</ul>
<p><img src="/images/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%E5%90%B4%E6%81%A9%E8%BE%BE1/image-20200817190256057.png" alt="image-20200817190256057"></p>
<p><img src="/images/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%E5%90%B4%E6%81%A9%E8%BE%BE1/image-20200817191426758.png" alt="image-20200817191426758"></p>
<p>同时更新θ0和θ1，右边的步骤是错误的。</p>
]]></content>
      <categories>
        <category>机器学习课程</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>机器学习入门</tag>
        <tag>吴恩达</tag>
      </tags>
  </entry>
</search>
